# Demo Status - MinIO + Spark + Trino Lakehouse

## Current Status: âœ… Running

All services are up and operational!

### Services Running

| Service | Status | URL | Notes |
|---------|--------|-----|-------|
| MinIO | âœ… Healthy | http://localhost:9001 | admin / password123 |
| Spark Master | âœ… Running | http://localhost:8082 | Data generation complete |
| Spark Worker | âœ… Running | - | 1 worker active |
| Trino | âœ… Healthy | http://localhost:8081 | Ready for queries |

### Data Generated

Successfully generated e-commerce dataset stored in MinIO (s3a://warehouse/):

- **customers**: 1,000 records in Parquet format
- **products**: 100 records in Parquet format  
- **orders**: 5,000 records in Parquet format (partitioned by status: cancelled, delivered, pending, shipped)

**Generation Methods Available**:
- Python version: `./run_spark_app.sh`
- Java version: `./run_spark_app_java.sh` âœ… Tested and working

### Trino Tables Created

- âœ… `hive.ecommerce.customers` - Working
- âœ… `hive.ecommerce.products` - Working
- âš ï¸ `hive.ecommerce.orders` - Created but partitions not auto-discovered (file-based metastore limitation)

## Quick Test Queries

```bash
# Connect to Trino
docker exec -it trino trino

# In Trino shell:
USE hive.ecommerce;
SHOW TABLES;

# Query customers
SELECT * FROM customers LIMIT 10;

# Analytics on products
SELECT category, COUNT(*) as count, AVG(price) as avg_price
FROM products
GROUP BY category
ORDER BY count DESC;

# Join query
SELECT c.first_name, c.last_name, c.city, c.state
FROM customers c
WHERE c.state = 'CA'
LIMIT 10;
```

## What's Working

âœ… MinIO object storage  
âœ… Spark data generation writing to MinIO (Python & Java versions)  
âœ… Parquet file format with Snappy compression  
âœ… Trino querying Parquet files from MinIO  
âœ… Hive-style directory structure (database.db/table/)  
âœ… Basic SQL queries on customers and products  
âœ… Aggregations and joins  
âœ… Java Spark application with Maven build

## Known Limitations

âš ï¸ **Partitioned Tables**: The file-based Hive metastore has difficulty with external partitioned tables. While the `orders` table is created and the data exists in MinIO, Trino cannot automatically discover the partitions with the current configuration.

**Impact**: You can query `customers` and `products` tables fully. The `orders` table exists but returns no results without a proper Hive metastore server.

**Future Enhancement**: Add a proper Hive Metastore service (with PostgreSQL backend) to support partitioned table discovery.

## Architecture Summary

```
Data Flow:
1. Spark â†’ Generates data â†’ Writes Parquet to MinIO (s3a://warehouse/)
2. Trino â†’ Reads Parquet files â†’ Provides SQL interface
3. MinIO â†’ Stores all data in S3-compatible object storage

Storage Structure:
s3a://warehouse/
â””â”€â”€ ecommerce.db/
    â”œâ”€â”€ customers/
    â”‚   â”œâ”€â”€ part-00000-*.snappy.parquet
    â”‚   â””â”€â”€ part-00001-*.snappy.parquet
    â”œâ”€â”€ products/
    â”‚   â”œâ”€â”€ part-00000-*.snappy.parquet
    â”‚   â””â”€â”€ part-00001-*.snappy.parquet
    â””â”€â”€ orders/
        â”œâ”€â”€ status=cancelled/
        â”œâ”€â”€ status=delivered/
        â”œâ”€â”€ status=pending/
        â””â”€â”€ status=shipped/
```

## Next Steps

1. âœ… Services running
2. âœ… Data generated  
3. âœ… Tables created in Trino
4. âœ… Basic queries working
5. ğŸ”„ (Optional) Add Hive Metastore service for partition support

## Stopping the Demo

```bash
# Stop services
docker-compose down

# Stop and remove all data
docker-compose down -v
```

---
**Last Updated**: 2025-11-25 07:08 UTC  
**Demo Type**: Parquet Lakehouse with MinIO + Spark + Trino
